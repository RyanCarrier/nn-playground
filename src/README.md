# Pt 1

Making 2 input and implementing AND
Then go to 3 and add or


prior knowledge makes the current plan;

3 inputs, 1 output

4? internal nodes with 2 layers?
 
 - I know we need more internal nodes than inputs, for combination inputs
 - we would also need multiple layers to then handle those combination inputs no? (like if you had first 2 bits are for and/or and second 2 are for inputs, you would need combination first 2 bits to know how to handle second 2 bits)
 - though with that it feels like layers is context dependant, and not actually node dependant...

Learning rate can scale linearly it will be fine

## pt2

Ok clearly not working and I thikn big issue is from wanting binary outputs with ananlogue inputs;

In future you will need things to decode inputs into input nodes (like pixels or shape coordinates??), but potentially also for output too. So having a analogue to binary converter is probably 'ok' and 'normally' done? idk there is transformers and diffusers and stuff, one of those is probably output

plus i know matricies are big shit for nn so probably need to drop the layers stuff anyway for matricicies somehow; matricies good cause SIMDeeznuts or something like that


